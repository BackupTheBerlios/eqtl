


          General informaion and instructions
          -----------------------------------

                          on

          setting up an Expression QTL project
          ------------------------------------



  This text brings the the reader to the level that the overall concept
  of the presented tools are understood sufficiently deep to set up an
  expression QTL project by his/her own.

  This file should be the first to read. It gives references to files
  and folders. Every file has a description itself that explains what
  it is doing and what options are expected. Every folder contains the
  file README with further information. This way one is incrementally
  guided through concepts and the source code.



1. Preparations
===============

1.1 Installation: Download of source code
-----------------------------------------

   The software does not come with an installer. This is not required
   since all parts are scripted and directly executable. The sources
   are made available via a git repository on http://eqtl.berlios.de.

   Once adapted to the workings of git, one can in a straight-forward
   manner share efforts between multiple projects. Every site can have
   their very own servers and their very own local changes to the system,
   while those parts that are of interest for other users can be sent
   back to the server.

   A first start is done with

	git clone git://git.berlios.de/eqtl

   to anonymously checkout the source tree. A username to allow
   for uploads back to the server can be added at a later time.


1.2 Database
------------

   The database is the core unit of the whole dataflow.
   It is storing the results and is used by the website
   to present the results. Moreover it is controlling the
   computation of the data.
   For the description of the tables of the database,
   see the database description file which is not there
   yet but will be soon...

   The name of the database should be that of your project
   and be specified in the configuration files.
   The database itself needs to contain the following tables.

	   +----------------------+
	   | Tables_in_Database   |
	   +----------------------+
	   | TableWithChipDetails |
	   | computation          |
	   | locus                |
	   | locusInteraction     |
	   | map                  |
	   | qtl                  |
	   | trait                |
	   +----------------------+

   As a start, it is suggested to directly import the schema
   that is put next to this document:

        yourMysqlSettings="-h yourHostname -u yourUsername"
	echo "create database yourDatabasename;"|mysql $yourMysqlSettings
        mysql $yourMysqlSettings yourDatabaseName < DatabaseSchema.txt

   In MySQL call "help alter table" for instructions how to change the
   properties of columns. This should only be required for the table
   representing the chip details and the implementation of enhancements
   to the system.

   TableWithChipDetails:
   ---------------------
   
        This table contains all information about the expression data.
        The name of the table may vary between projects and was thus
        made a parameter for the configuration.

   computation:
   ------------

        This table controls all computations: all jobs that need to
        be computed are one entry in this database. The jobname is in
        the format:

	 [scanone|scantwo]_probesetid_lodThreshold_numberOfPermutations_(covariate1{_add|_int},covariate2{_add|_int}).csv.gz

        Each entry has a unique id, the computation_id which is linked
        to the results of this job.  In that way, old results can be
        determined and can be deleted if a new compuation was done.
        The status of a job can either be

		QUEUED	     it needs to be computed for the first time
		RECALCULATE  job needs to be recalculated
		PROCESSING   following QUEUED when job is executed
			     but not yet uploaded
		REPROCESSING which follows RECALCULATE
		DONE         the results are already uploaded

   locus:
   ------

        This table gives information about the determined loci,
        for example like the chromosome and the centiMorgan
        position.

   locusInteraction:
   -----------------

        This table contains all results from the scantwo analyses.
        It tells which two loci are interacting for a specific
        probeset_id and specific covariates. There is also information
        about the 95 percentile, the LOD score and much more given.
        For a detailed description please see the database documentation.

   map:
   ----

        This table stores the marker information from the 
        experiment.

   qtl:
   ----

        Table representing the results of the scanone analysis.
        Locus, Probeset_ids, LOD-scores, cMorgan positions and
        much more information are given.

   trait:
   ------

        This table contains information about every single probeset
        like expression high, variance, standarddeviaten.


1.3 Data Preparation
--------------------

   Every project will generate data in a different format. The ultimate
   challenge is to prepare the data in a way that any particular job 
   receives (as a single file) the right covariates, the complete genotyping
   data, and the right gene's expression values to perform the computation.
   Also important it is to have every data file in the right order, i.e. the
   mice in the genotyping should be ordered in the same way that the mice
   in the expression data is.  The joining of the data sources should
   be performed prior to the submission of the job, to help avoiding
   potential problems.

   The data shall be formatted in a way that the function qtl::read.cross
   understands it directly. The expression data then commonly is in the 2nd
   or third column, which is identified by the variable phenocol (parameter
   PHENOCOL in conf*/data.conf). 
   


1.4 Config files and template files
-----------------------------------

   Most scripts that are prepared for one experiment are available
   and applicable for all experiments using this infrastructure, i.e.
   all scripts except for those involved in the upload of wet-lab data.
   For the latter, only conceptional drafts are available that should
   be adapted.

   The configuration files in the folder 'conf_template' shall be
   copied into a folder that is named 'conf_projectname', substitute
   'projectname' with the respective name of your project. You may have
   multiple projects maintained in parallel. Then edit all the
   files in conf_projectname/ to suite your project.

   The script 'update.sh' will perform the substitution of all the
   placeholders. The substitutions will be performed in the alphabetic
   order of the filenames of those files that contain the rules.
   Nevertheless, dependencies between rules should be strictly avoided.
   The substitutions will be performed on all files ending with ".template"
   and a new file will be created, without the ".template" suffix, that
   has all the substitutions performed. 



2. Website
==========

   Once that update.sh was executed, your website shall be ready. There
   are two websites to take care of. The scripts in 

        website/*

   perform the distribution of data and present an overview on the
   current state of data generation to the project participants. The
   jobs that are executed remotely will query the website and request
   new data to be submitted. The setup expected to be ready involves

	- Apache with FastCGI Perl interface
	- a MySQL database

   For Debian install the packages libfcgi-perl, libapache2-mod-fastcgi,
   php5-mysql, libapache2-mod-php5 and ensure that the website folder
   is accessible by the apache.


2.1  Communication of the project's internals
---------------------------------------------

   The script

	website/index.php.template

		provides the web interface to human users
		and also gives an introduction to the working of
		the infrastructure

	website/showSRC.pl.template

		displays source code of scripts on the website

2.2  Data Computation
---------------------

	website/evaluateQuery.R

   		is the main script to start the computation of the data.
		It is executed on the machine that performs the computation
		and resides in this folder only to be easily accessible for
		its distribution.

		To run this script, make sure that R/qtl is installed.
		Started with this script, several files are used
		that need to be on a web server with apache and fcgi.
		The path to those files and the names of the files,
		which can be changed if required need to be determined
		in the config files.


	website/recalc.pl.template

	        is the first file to be called as it
		determines what job should be executed next,
		i.e. what clinical parameter shall be modelled
		by which gene's expression levels with which
		set of covariates and those additive or
		interacting.

	        This script queries the database for the next job to compute.
		The jobname is a concatenation, joined by interspersing "_"
	     	characters, of the following pameters in the exact same order:
		   [scanone|scantwo]	single or combined effects
		   probesetid		trait to be modelled
		   lodThreshold		always set to 3.6
		   numberOfPermutations	always set to 1000
		   (covariate1{_add|_int},covariate2{_add|_int})
					list of covariates to be taken into account
	        The extension _add or _int tells wether the covariate
	        should be considered interactive or additive in the
	        model.  If this information is missing, the covariate is
	        automatically considered to be interactive.

		The specification the syntax of jobnames can obviously be changed,
		but many parts of the code as it is written today do depend on the
		current formatting. 

		When no more jobs are pending to be computed, the script returns q("no")
		which causes evaluateQuery.R to stop and to leave R.


	website/getRscript.pl.template

		prepares a script that is executed with the statistics
		suite R (http://www.r-project.org) and the library R/qtl
		(http://www.rqtl.org).	Albeit written in Perl, this
		script returns R code.

		This script uses the path to the data file (expression
		data, genotyping and quantitative information
		(covariates)).	The path needs to be specified in the
		config files.

		The format of the required data will vary across projects.
		There is yet not ultimate decision on how to achive
		project independence with respect to data formats and to
		what degree this is achievable. More details are found
		in the 'upload' section of this document.


	website/prepareRqtlInputData.pl.template

		prepares the input for the getRscript.pl from the genotype
		data, the expression data and the clinical parameters,
		all for a single gene to be analysed.

		The data is prepared for to be accepted by the
		qtl::read.cross() function, which is executed from the
		R script that is generated by getRscript.pl.

   After the execution of all those scripts, the result file
   is written to the specified directory (default: ~/myTmp).
   These files need to be retrieved from he host that performs
   the computation to be then uploaded to the database.

   Just a short checklist before you run evaluateQuery.R:

   - make sure the database is reachable and the computation
     table contains jobs with status QUEUED or RECALCULATE
   - make sure the jobnames have the right syntax
   - make sure you have the right data files and they are
     in the config files
   - make sure evaluateQuery.R, recalc.pl, getRscript.pl
     and prepareRqtlInputData.pl are reachable and updated
     with the latest config files
   - make sure that the paths to the files in the config 
     files are correct

2.2  Results Upload to Database
-------------------------------

   For the upload of data please refer to the document
   'DataHandling.txt' in this folder.


2.3  Results Presentation
-------------------------

   All data that is presented on the interactive web site
   was at some stage stored in the database.

        website/eqtl/*.php

		represents the web interface for the presentation 
		of all results.

		qtl.php
			presentation of the quantitative effect
			that single locus has

		trait.php
			details on the gene, whose expression levels
			are attempted to be modelled by the genotype.

   
3.  Analyses
============

   cis - trans QTL

   QTL density plots

   correlations between genes and between genes and phenotypes

