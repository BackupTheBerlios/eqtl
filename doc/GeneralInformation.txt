1. Database
-------------------
-------------------

   The database is the core unit of the whole dataflow.
   It is storing the results and is used by the website
   to present the results. And it is controlling the
   computation of the data.
   For the description of the tables of the database,
   see the database description file which is not there
   yet but will be soon...
   I am not sure if there is an upload script to create
   the database but if not there will be one soon...
   The name of the database is irrelevant, as long as
   you write it to the config files. The database itself
   needs to contain the following tables:

   +--------------------+
   | Tables_in_Database |
   +--------------------+
   | BEARatChip         |
   | computation        |
   | locus              |
   | locusInteraction   |
   | map                |
   | qtl                |
   | trait              |
   +--------------------+

   BEARatChip:
   
   this table contains all information
   about the expression data.
   This is the only table where the name should
   be choosen dependent from the data, but we haven't
   included this to to be a config parameter so at the
   moment this name needs to be used.

   computation:

   this table controls all computations:



2. Website
3. Config files and template files
4. Data Computation
--------------------
--------------------
   The main script to start the computation of the data is

	scripts/evaluateQuery.R

   To run this script, make sure that Rqtl is installed
   Startet with this script, several files are used that
   need to be on a web server with apache and fcgi.
   The path to those files and the names of the files,
   which can be changed  if required need to be determined
   in the config files. The first file to be called is

	website/recalc.pl

   This script queries the database for the next job to
   compute. The jobname is in the following syntax:
	[scanone|scantwo]_probesetid_lodThreshold_numberOfPermutations_(covariate1{_add|_int},covariate2{_add|_int}).csv.gz
   The extension _add or _int tells wether the covariate
   should be considered interactive or additive in the model.
   If this information is missing, the covariate is 
   automatically considered to be interactive.
   Of course the jobname syntax can be changed, but in
   this case, the code needs to be adopted to the new syntax.
   If there are no more jobs to do, the script returns q("no")
   which causes evaluateQuery.R to stop and to leave R.
   The jobname is parsed, and

	website/getRscript.pl 

   is called. This script returns the R code to be executed.
   This script uses the path to the data file (expression 
   data, genotyping and quntitative information(covariates))
   The path needs to be specified in the config files.
   The format of the required data will soon appear in this
   file in a special section. Of course you don't need to
   stick with this format specification, but be aware that
   you need to adopt the code if you change it.
   The generated R-code needs the script

	website/prepareRqtlInputData.pl 

   This script generates an output which contains the needed
   information from the data and can be read via read.cross()
   from the R script generated by getRscript.pl.

   After the execution of all those scripts, the result file
   is written to the specified directory (default: ~/myTmp)
   and the results can be uploaded to the database.

   Just a short checklist before you run evaluateQuery.R:

   - make sure the database is reachable and the computation
     table contains jobs with status QUEUED or RECALCULATE
   - make sure the jobnames have the right syntax
   - make sure you have the right data files and they are
     in the config files.
   - make sure evaluateQuery.R, recalc.pl, getRscript.pl
     and prepareRqtlInputData.pl are reachable and updated
     with the latest config files
   - make sure that the pathes to the files in the config 
     files are right
   
5. data uplaod
